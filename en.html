<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Karen Palacio,Ø</title>
    <link rel="stylesheet" href="./styles.css">
    <link rel="icon" href="./favicon.ico" type="image/x-icon">
<link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@300&display=swap" rel="stylesheet">
  </head>
<link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@300&display=swap" rel="stylesheet">
  <body>
        <img id="header" src="menades.png"/>
        <div class="navbar">
                            <div class="linksN flex-container">

            <a href="#About">About</a>
            <a href="#Cursos">Courses</a>
            <a href="#Proyectos">Projects</a>
            <a href="#Statement">Statement</a>
            <a href="#links">Contact</a>
                            </div>
        </div>
    <main>
        <h1 id="name1">Karen Palacio,     Ø</h1>
        <div class="links" id="links">
		<a target="_blank" href="https://docs.google.com/document/d/12fzuPOiaMMVhUIN0TUjhRLEBD4J6Ir2X/edit?usp=sharing&ouid=117618929164324557061&rtpof=true&sd=true"> CV </a> || <a target="_blank" href="https://instagram.com/kardaver">instagram</a> || <a target="_blank"  href="https://www.youtube.com/channel/UCDTXCf0EitxmvFfyRDtppuQ/videos">youtube</a> ||<a target="_blank"  href="https://github.com/karen-pal">github</a> || <a target="_blank" href="https://soundcloud.com/kardaver"> soundcloud </a>  || email: karen.palacio.1994@gmail.com || <a target="_blank" href="https://drive.google.com/file/d/1f8xAkIXg5BOZLeY5vXjbLT1ta8iJh8HO/view?usp=sharing"> Dossier </a>
        </div>
        <br><br>
        <!--button type="button" class="collapsible">Sobre mí</button!-->
	<a class="links" id="lang" href="index.html">Ver en Español</a>

        <h1 id="About"> About </h1>
	<p>
    Karen Palacio is a live coder, programmer, and interdisciplinary digital artist from Córdoba Capital, Argentina. She holds a degree in Data Science from FaMAFyC and is studying for a Bachelor's degree in Computer Science at FaMAFyC.
    <br><br>She has extensive experience in the Software industry, specializing in the development of Conversational Artificial Intelligence applications. She was the Technical Lead of the Artificial Intelligence department at Kunan, and is currently focused on AI applications for airlines.
    <br><br>She researches the development, adaptation, and use of open-source software for performances and installations, aiming to weave complex and multidimensional multimedia texts.
    <br><br>In her artistic productions, she seeks to demonstrate the flexibility of programming as a discursive technique, digitizing and conquering more traditional spaces. She has performed improvisational code for visuals at numerous festivals (such as Cosquín, Mutek, Lollapalooza, Festival De La Salamanca, Festical Latinoamericano de Artes y Tecnologías (Chile), MASS Encuentro(Colombia)); the Metaverse (Decentraland’s MMF); noise meetings (such as Santo Noise, Experimentalia); technology conferences (such as Khipu, WiDS, FITs); museums (such as the Emilio Caraffa Museum, CCEC, CaSO, El Gran Vidrio); and electronic parties - among other places - programming for up to 8 hours straight live. She has showcased her audiovisual work at Tecnópolis, Germany, Chile, Colombia, Venezuela, the Cordoba Art Fair, the MAPA fair, the World Circular Economy Summit, the Cordoba Music Biennial, among other places. She has live coded alongside Horacio Banegas in seven Argentine provinces.
    <br><br>Karen Palacio maintains an interdisciplinary artistic practice that involves researching and producing in implementation-reflection loops, aiming to understand what it means to articulate artistic-technological discourses in the Global South. Her performances, installations, and audiovisual works are critically and deeply connected to the computational realm, the histories of computing, and archives. Her work is intrinsically linked to activism for knowledge freedom, feminism, and the pursuit of technological sovereignty, developing and engaging with Free Software in her processes, and reinterpreting technologies she is familiar with from her career as an industrial programmer.
	<br><br>In 2023, she won the 14th Edition Itaú Prize in the Art and Artificial Intelligence category with her work "Trabajo". That same year, she received funding for production through the "Contemporary Art MediaLab CCEBA 2023: Artistic and Technological Practices" program with her project on Artificial Intelligence interaction titled "Lenguaje Frontera: Other Infinities in the Fissures of Technical Systems". Throughout 2023, she was selected to participate in the federal program Presente Continuo. She is part of the Amplify DAI program. She lives and works in Córdoba, Argentina.
</p>

        

<img class="img-responsive" src="cosquin.jpg"/>
<h1 id="Cursos"> Courses and Talks Given </h1>
	<h2> Borges corpus: a dataset of Latin American short stories for NLP in Spanish </h2>
	<p>
	In August 2024, I gave an introductory talk about the dataset I created in 2018 and have actively maintained since that year.
	<br><br>Borges contains two large datasets: one dataset (full_corpus.csv) of short stories by Latin American authors, and another dataset focused on performing sentence-by-sentence sentiment analysis of Borges' work. The full_corpus.csv dataset includes 719 stories from 58 authors across Latin America.
	<br><br>In addition to these datasets, I released the programs I wrote to create them, along with a couple of notebooks that demonstrate different uses for the dataset.
	<br><br>
	You can access the introductory talk on my YouTube channel:
	<div class="video-responsive">
	<iframe width="560" height="315" src="https://www.youtube.com/embed/1xyeEIL5i_0" title="Borges YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	</div>
	<br><br>
	</p>
	<p>
	And the datasets, the code that generated them, and the notebooks demonstrating their usage can be found 
	<a href="https://github.com/karen-pal/borges" target="_blank"> in the Borges GitHub repository.</a>
	</p>
	<a href="https://github.com/karen-pal/borges" target="_blank">
		<img class="img-responsive" src="borges.png"/>
	</a>

<h2>Computational Sovereignty and co-creation with Artificial Intelligence</h2>
<p>
During January 2024, I travelled to Concepción, Chile as a guest artist for the Arts and Technologies Festival Toda La Teoría del Universo. Among other activities, I taught a theoretical-practical workshop on relationships with different AI models focused on audiovisual creation, maintaining loops of implementation/reflection. We got in contact with a series of intuitions that contextualize the key technologies of the current generative environment of Machine Learning. On a practical level, we explored different ways of interacting with Machine Learning models, building prototypes and workflows with varying complexities.

Putting marginal notes at the center, together we reflected on creative and critical exploration - trying to create a network that increases the computational sovereignty on this side of the planet and allows us to think beyond the viewpoint of "users". For this, we used different scientific computing nodes from the network of scientific computing of the public universities of Argentina, for audiovisual creation with Artificial Intelligence.


<br>
<br>
<a href="https://karen-pal.github.io/soberania/en.html" target="_blank">I wrote a journal based on the ideas explored in the workshop, it can be accessed following this link.</a>
</p>
<a href="https://karen-pal.github.io/soberania/en.html" target="_blank">
        <img class="img-responsive" src="ttu.jpg"/>
</a>
<h2>Audio-reactive, rhythmic, and synesthetic Livecoding</h2>
<p>
During November 2023, I travelled to Cali, Colombia, participating in the <a target="_bank" href="https://www.instagram.com/massencuentro/" >international meeting of Arts and Digital Cultures MASS</a>. I participated as a guest artist and representative of the <a target="_blank" href="https://presentecontinuo.org/">Continuous Present program, a national program of artists, scientists, and technologists with a federal character, supported by the Bunge and Borne Foundation, Williams Foundation, and Andreani Foundation.</a> In Cali, I taught the collaboratory: "Audio-reactive and synesthetic live coding."
<br>
<br>
Live coding of visuals is a technique that mixes programming, improvisation, and rhythm with live audiovisual development. It is a challenge of being in the present and attentive listening that offers surprising visual results.
<br>
<br>

In this theoretical-practical collaboratory, we introduced ourselves to the open source tool Hydra and my person approach to live coding technique in order to create live visual performances and audio-reactive generative graphics. This experience can help creative individuals of all levels to learn the basics of audio reactivity, audiovision, and synesthetic experiences, and different techniques for the creation of generative art.

<br>
<br>
The main focus of the collaboratory was to rediscover the visual through listening: based on the concepts of presence and listening, and Deep Listening exercises, facing the act of visual improvisation as a moment where we understand ourselves from our past and what we expect from the future.

<br>
<br>
Another focus of these sessions was to see how the different components of Hydra - and a little bit of math-magic - allow our animations to maintain a tempo and be transformed by music. We intuitively saw how different visual elements can be modified by different specific musical instruments - even if they are playing at the same time. For this, we gently saw some of the mathematics behind signal analysis. We will try to make this serve as a seed that complicates, feeds, and dialogues with our livecoding production, increasing the potential for collaborative play with other audiovisual and sound producers.

<br>
<br>
We livecode seeking a good balance between production and reflection. Finally, we concluded the collaboratory with a collective AV improvisation performance - at the closing act of the MASS Encounter.
</p>
<br><a target="_blank" href="https://disenoensociedad.com/">Enter the event page here</a>
<div class="video-responsive">
<iframe width="560" height="315" src="https://www.youtube.com/embed/v6Aoqrg4pb8?si=_Fis5OyrNQ19Chcb" title="Colab YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<h2>Art and AI: Beyond usage and surfaces</h2>
<p>During October, I carried out various actions related to liberating knowledge and setting up mechanisms that allow artists from all over the country to acquire knowledge and computing capacity for deep production with AI.

One of those actions was the talk "Practical directions for relationships with AI, to whom it may concern", given by invitation of Bruno Mesz, within the framework of the UNTREF Art and Artificial Intelligence subject. I asked it to be open and recorded to facilitate access to this information.
</p>
<div class="video-responsive">
<iframe width="560" height="315" src="https://www.youtube.com/embed/0VCcrVSqt3c?si=GbeLyA84LxxIF2L3" title="Course YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<h2>The construction of meaning in computational art: composition of creative languages</h2>
<p>
During 2022, I gave three editions of a course on the design, implementation, and critical analysis of programming languages, aimed at artists. In this course, we implemented programming languages from scratch for audiovisual creation. This course is called "The construction of meaning in computational art: composition of creative languages."

How can we write programs that interpret other programs? How can we build meaning in the production of a work that interacts intimately with the computational medium? When does a program "become" art?
        <img class="img-responsive" src="semiosis.png"/>
</p>
<br><a target="_blank" href="https://wipartedigital.com/workshops/la-construccion-de-sentidos-en-el-arte-computacional/">Enter the course page here</a>
<br>
<br>
        <h1 id="Proyectos">Selected works</h1>
	<h2>Process Log: Miel de Purga / Purge Honey</h2>
<p>
On this page, I recorded in a log format the creative processes of Miel de Purga/Purge Honey. Purge Honey is an interdisciplinary experience that was produced and inaugurated within the framework of the MASS Encounter, in Cali, Colombia. It is traversed by sound art, performance, creative programming, dance, live coding of visuals, choreography, and it is rooted politically and geographically on the 2021 Cali outbreak. I was part of this collaboration thanks to the co-creation will of Beatriz Sterling, Mario Ortiz, and Javier Blanco. This log contains photos and collages I made, reflective writings (and others more technical), sounds, compositions, and videos. I wanted to register some organic collaboration methodologies that were emerging among the co-creators. Also, I wanted it to be very much in the first person - as a person from Cordoba - Argentina, knowing the events of the recent outbreak in Cali, Colombia, and feeling crossed by the parallels with Cordoba/Argentina of the past and the present.
<br><br>
Now more than ever I feel it present - the memories of the peoples are muscles that need to be exercised, and the peoples of the South are going to have to fight for our self-definition eternally.
</p>
        <br><a target="_blank" href="https://karen-pal.github.io/miel/">Ingresar aquí a la bitácora Miel</a>
        <h2> Trabajo / Work </h2>
<p>
    "Work" is a soundless visual essay, exploring the material realities and geopolitical asymmetries behind the illusion of digitalization. <br><br>It was exhibited at the First Megashow of Digital Art, at Tecnópolis, 2022. For its creation, I used my custom implementation of the livecoding language Hydra - modified by me to incorporate pre-Columbian graphics, and made it interact with Artificial Intelligence technologies to generate images from English texts.
    <br><br>In 2023, it won the Itaú Visual Arts Prize Edition 14, in the category of Art and Artificial Intelligence. It was exhibited at the Emilio Caraffa Museum during the months of July, August, and September 2023.
    <br><br>It is part of a broader graphic experimentation in my work: how to speak about realities for which there is no record, or the record is scarce/ of low quality, or inaccessible on the internet, due to geopolitical asymmetries?
</p>
        <div class="video-responsive">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/Py0BTX6BBFE" title=" Trabajo YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
        <h2> internetSur </h2>
	<p>
    "internetSur" (southInternet) is an audio-rhythmic visual essay, exploring the material realities and geopolitical asymmetries behind the illusion of digitalization.
    <br><br>It was the opening of the Festival of Innovation and Social Technology (FITS) edition 2022. DJ Octavio Octavio performed the set that plays. In its creation, I engaged with Artificial Intelligence technologies to generate images from English texts.
    <br><br>It is part of a broader graphic experimentation in my work: how to speak about realities for which there is no record, or the record is scarce/ of low quality, or inaccessible on the internet, due to geopolitical asymmetries?
</p>

        <div class="video-responsive">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/LT9od_RYjDo" title="internetSur YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
	<h2>Exploration Log: Synesthetic</h2>
	<p>
	    On this page, I have recorded in log format the process, intermediate results, reflections, and visualizations proposed while navigating between configuring noise instruments in Bitwig, writing texts that could serve as prompts for image generation models using Machine Learning, and the visual results thereof. I developed an initial bank of instruments in Bitwig while writing the prompt texts to feed into a new AI model I was testing. I allowed myself to be drawn in until reaching an unexpected visual result. I took it as a starting point from which to operate sound, imagining the sounds of the image. Then, by operating with Hydra and editing video, I arrived at an audiovisual piece.
	    <br> Optimized for desktop.
	</p>
	<br><a target="_blank" href="https://karen-pal.github.io/ser_ser_ser/">Enter the synesthetic log here</a>

	<h2>Exploration Log: Synesthetic</h2>
	<p>
	    On this page, I have recorded in log format the process, intermediate results, reflections, and visualizations that came up to me while navigating between configuring noise instruments in the DAW Bitwig, writing texts that could serve as prompts for image generation models using Machine Learning, and the visual results thereof. I developed an initial bank of instruments in Bitwig while writing the prompt texts to feed into a new AI model I was testing. I allowed myself to be drawn in until reaching an unexpected visual result. Then I took those visuals results as starting points from which to explore digital sound-making, imagining the sounds of the being represented in the images. Then, by operating with Hydra and editing video, I arrived at an audiovisual piece.
	    <br> Optimized for desktop.
	</p>
	<br><a target="_blank" href="https://karen-pal.github.io/ser_ser_ser/">Enter the synesthetic log here</a>
	<h2> Web Essay: Digital Art in the Global South </h2>
	<p>
	Following the idea of digital&site-specific, I conceived this web essay for mobile devices, intended to document reflections about my practice as a digital artist, committed to the geopolitical issues of my here and now, as a digital artist from Argentina, South America.
	<br> Optimized for mobile.
	</p>
	<br><a target="_blank" href="https://karen-pal.github.io/construccion/">Enter the essay here</a>

	<h2> Sentido/Sense </h2>
	<p>
	Online drawing environment that blurs, exploring foundational ideas about digital imagery.
	</p>
	<br><a target="_blank" href="https://karen-pal.github.io/sentido/">Enter the drawing environment here</a>    
	<h2> Pose Shader </h2>
	<p>
	Online drawing environment used to modify shaders through poses. It utilizes machine learning models for pose detection, and I wrote specific shaders for this page. It's part of a larger project called "Development Log, or what is programming".
	</p>
	<br><a target="_blank" href="https://karen-pal.github.io/poseShader/">Enter the environment here</a>
	<h2> Development Log, or What Is Programming. </h2>
	<p>
	Proposal for an in-person installation, for reflective interaction with a custom-developed gestural drawing system (pose shader).
	<br><br> Selected for the Art and Technology Laboratory by the Municipality of Córdoba. 
	</p>
	<br><a target="_blank" href="https://karen-pal.github.io/poseShader/about.html">Enter the proposal page here</a>
	<h2> Own Programming Language: M(é)nad(e)\s </h2>

	<p>
	A complex programming language conceived as an active matrix: an act of negotiation, perhaps drawing. Explorations within slow programming and drawing.
	</p>
	<br><a target="_blank" href="https://github.com/karen-pal/menades">Enter the page here</a>
	<h2> Own Programming Language: naive </h2>

	<p>
	A language for geometric drawing and its compiler implemented in JavaScript. Result of simplifying compiler operation and implementing definitions naively - part of the course Construction of Meanings in Computational Art: Composition of Creative Languages.
	</p>
	<br><a target="_blank" href="https://karen-pal.github.io/poseShader/">Enter the language page here</a>
	<br><br>

        <br><br>
	<h1 id="Statement"> Statement </h1>
	<!--button type="button" class="collapsible">Artist Statement</button--!>
	<p>
	In my artistic practice, I investigate and produce from a critical stance, with a methodology that keeps me in loops of implementation-reflection. I understand what I do as a militancy for the freedom of knowledge, starting from a feminist and ecological standpoint of technology.
	<br><br>As a VJ, I have experienced the potential of visuals: they can shape complex, polysemic, open, and dynamic texts. On the other hand, visuals can also be electronic banners or decorations. Visuals can weave essays that establish relationships with the architecture and history of a place, and they can be thought of as live editing: they can contrast, reinforce, modify, unveil, conceal, denounce, among other operations. On the other hand, visuals are usually thought -paradoxically- not to be seen: stimuli with little information, redundant and conventional visual marks, designed to "not compete" with the rest of what happens at an event/place. In my artistic pursuits, I try to show the semantic and performative potential of the visual to dialogue with the auditory, and to transform an event into something that constructs demanding and multidimensional texts.
	<br><br>I am constantly developing and engaging with free software such as Hydra, openFrameworks, p5js, Blender, programming languages like Python, JavaScript, Rust, Haskell, and C++, libraries, models, and machine learning architectures like NLTK, spaCy, VQGAN+CLIP, and Stable Diffusion. I combine them with live coding to operate them live. I understand visual live coding as a highly demanding physical, mental, and emotional performative act, and an exercise in presence and attention. During my performances, I try to establish a circuit between the participants, the sound performers, the lighting situation of the place, the architecture of the physical place, the computer with which I am communicating through programming languages, my body, and the graphic signs of the visuals. In this way, I consciously try to establish loops of co-constitution.
	</p>

        <div class="links">
        <a target="_blank" href="https://docs.google.com/document/d/12fzuPOiaMMVhUIN0TUjhRLEBD4J6Ir2X/edit?usp=sharing&ouid=117618929164324557061&rtpof=true&sd=true"> CV </a> || <a target="_blank" href="https://instagram.com/kardaver">instagram</a> || <a target="_blank"  href="https://www.youtube.com/channel/UCDTXCf0EitxmvFfyRDtppuQ/videos">youtube</a> ||<a target="_blank"  href="https://github.com/karen-pal">github</a> || <a target="_blank" href="https://soundcloud.com/kardaver"> soundcloud </a>  || email: karen.palacio.1994@gmail.com
        </div>
    </main>
	<script>

document.addEventListener("DOMContentLoaded", function() {
  var lazyloadImages;    

  if ("IntersectionObserver" in window) {
    lazyloadImages = document.querySelectorAll(".lazy");
      console.log(lazyloadImages);
    var imageObserver = new IntersectionObserver(function(entries, observer) {
      entries.forEach(function(entry) {
        if (entry.isIntersecting) {
          var image = entry.target;
          image.src = image.dataset.src;
          image.classList.remove("lazy");
          imageObserver.unobserve(image);
        }
      });
    });

    lazyloadImages.forEach(function(image) {
      imageObserver.observe(image);
    });
  } else {  
    var lazyloadThrottleTimeout;
    lazyloadImages = document.querySelectorAll(".lazy");
    
    function lazyload () {
      if(lazyloadThrottleTimeout) {
        clearTimeout(lazyloadThrottleTimeout);
      }    

      lazyloadThrottleTimeout = setTimeout(function() {
        var scrollTop = window.pageYOffset;
        lazyloadImages.forEach(function(img) {
            if(img.offsetTop < (window.innerHeight + scrollTop)) {
              img.src = img.dataset.src;
              img.classList.remove('lazy');
            }
        });
        if(lazyloadImages.length == 0) { 
          document.removeEventListener("scroll", lazyload);
          window.removeEventListener("resize", lazyload);
          window.removeEventListener("orientationChange", lazyload);
        }
      }, 20);
    }

    document.addEventListener("scroll", lazyload);
    window.addEventListener("resize", lazyload);
    window.addEventListener("orientationChange", lazyload);
  }
})
    </script>
  </body>
</html>
